{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab56009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils import *\n",
    "from plotting import *\n",
    "from models import *\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40a462",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9c46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse-AE doubleTmaze\n",
      "sparse-AE cylinder\n",
      "sparse-AE permanence\n",
      "sparse-AE thorndike\n",
      "AE doubleTmaze\n",
      "AE cylinder\n",
      "AE permanence\n",
      "AE thorndike\n"
     ]
    }
   ],
   "source": [
    "tasks = ['doubleTmaze', 'cylinder', 'permanence', 'thorndike']\n",
    "model_types = ['sparse-AE', 'AE']\n",
    "\n",
    "results = {}\n",
    "for model_type in model_types:\n",
    "    results[model_type] = {}\n",
    "    for task in tasks:\n",
    "        print(model_type, task)\n",
    "        \n",
    "        # Load dataset and model\n",
    "        dataset, position = load_dataset(directory='datasets/' + task, task=task)\n",
    "        model = Conv_AE(n_hidden=1000).to('cuda')\n",
    "        model.load_state_dict(torch.load('saved_models/main_{}_{}_1000hidden.pth'.format(task, model_type)))\n",
    "\n",
    "        # Get latent embeddings\n",
    "        embeddings = get_latent_vectors(dataset, model)\n",
    "        embeddings[embeddings < 1e-5] = 0\n",
    "        \n",
    "        # Generate ratemaps and cleaned ratemaps\n",
    "        ratemaps = generate_ratemaps(embeddings, position, n_bins=60, filter_width=4, n_bins_padding=10)\n",
    "        cleaned_ratemaps = clean_ratemaps(ratemaps)\n",
    "        \n",
    "        # Place field density\n",
    "        all_num_fields, all_centroids, all_sizes = stats_place_fields(cleaned_ratemaps, min_pix_cluster=0.03)\n",
    "        place_field_density = np.histogram(all_num_fields, bins=np.max(all_num_fields) + 1, density=True)[0]\n",
    "        \n",
    "        # Homogeneity in tiling of 2D space\n",
    "        homogeneity_tiling = homogeneity_2Dtiling(all_centroids)\n",
    "        \n",
    "        # Distribution of distances to walls\n",
    "        occupancy_map = generate_occupancy_map(position, n_bins=60, filter_width=0, n_bins_padding=10, norm=False)\n",
    "        distances = dist_to_walls(all_centroids, occupancy_map)\n",
    "        dist_size_corr_slope, b = np.polyfit(distances, all_sizes, 1)\n",
    "\n",
    "        # Average spatial information\n",
    "        unfiltered_ratemaps = generate_ratemaps(embeddings, position, n_bins=30, filter_width=0, n_bins_padding=0)\n",
    "        cleaned_unfiltered_ratemaps = clean_ratemaps(unfiltered_ratemaps)\n",
    "        occupancy_map_norm = generate_occupancy_map(position, n_bins=30, filter_width=0, n_bins_padding=0, norm=True)\n",
    "        avg_spatial_info = np.mean(spatial_information(cleaned_unfiltered_ratemaps, occupancy_map_norm))\n",
    "    \n",
    "        # Linear decoding error\n",
    "        #linear_score, baseline_score, ratio = linear_decoding_score(embeddings, position, n_baseline=100)\n",
    "        norm_factor = (np.max(position) - np.min(position)) * np.sqrt(2)   # uses the diagonal of the square as max distance.\n",
    "        mean_decoding_error_embeddings = linear_decoding_error(embeddings, position, norm=norm_factor)\n",
    "        \n",
    "        ratemaps_reshaped = ratemaps.reshape(ratemaps.shape[1] * ratemaps.shape[2], ratemaps.shape[0])\n",
    "        pos_values = np.linspace(np.min(position), np.max(position), ratemaps.shape[1])\n",
    "        position_for_ratemaps = np.array([[i, j] for i in pos_values for j in pos_values])\n",
    "        mean_decoding_error_ratemaps = linear_decoding_error(ratemaps_reshaped, position_for_ratemaps, norm=norm_factor)\n",
    "        \n",
    "        # Store the results in the dictionary\n",
    "        results[model_type][task] = {\n",
    "            'ratemaps': cleaned_ratemaps,\n",
    "            'place_field_density_hist': place_field_density,\n",
    "            'homogeneity_2Dtiling': homogeneity_tiling,\n",
    "            'distances_to_walls': distances,\n",
    "            'all_sizes': all_sizes,\n",
    "            'dist_size_corr_slope': dist_size_corr_slope,\n",
    "            'avg_spatial_info': avg_spatial_info,\n",
    "            #'linear_decoding_score': linear_score,\n",
    "            #'linear_decoding_baseline_score': baseline_score,\n",
    "            #'linear_decoding_ratio': ratio,\n",
    "            'mean_decoding_error_embeddings': mean_decoding_error_embeddings,\n",
    "            'mean_decoding_error_ratemaps': mean_decoding_error_ratemaps\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79548201",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf995b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Save the results dictionary to a file in the 'results' folder\n",
    "file_path = os.path.join('results', 'spatial_allModels.pkl')\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8b05d",
   "metadata": {},
   "source": [
    "#### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee727aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and print the results to check\n",
    "with open(file_path, 'rb') as f:\n",
    "    loaded_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2085a17",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d4264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
